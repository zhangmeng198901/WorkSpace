# MySQL复制：

扩展方式：
    Scale Up
    Scale Out
MySQL的扩展：
    复制：每个节点都有相同的数据集
        向外扩展的解决方案
        从节点向主节点请求二进制日志中的事件于本地，并执行replay
        单向进行
        M/S 
复制的功用：
    数据分布
    负载均衡：只针对读节点 
        任何一个节点执行的写操作都是完整的写操作
    数据备份
    高可用和故障切换
    MySQL升级测试


# 实现复制结构
从节点：
    I/O Thread：从Master请求二进制日志时间，并保存于中继日志中；
    SQL Thread：从中继日志中读取日志时间，在本地完成重放
主节点：
    dump Thread：为每个Slave的I/O Thread启动一个dump线程，用于向其发送binary log events;

特点：
    1、异步复制：
    2、主从数据不一致比较常见；

复制架构：
    M/S，M/M 
    一主多从
    从服务器还可以再有从服务器
    一从多主

二进制日志时间记录格式：
    STATEMENT：基于语句的复制，在主服务器上执行的SQL语句，在从服务器上执行同样的语句。MySQL默认采用基于语句的复制，效率比较高； 
    ROW：基于行的复制：把改变的内容复制过去，而不是把命令在从服务器上执行一遍. 从mysql5.0开始支持；推荐，但占用空间；
    MIXED：混合类型的复制: 默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。



# 实现
    主从、主主、半同步复制、复制过滤器

## 主从配置过程：
   主节点：
        1. 启动二进制日志
            vim /etc/my.cnf.d/server.cnf 或者/etc/my.cnf
            [mysqld q]
                log-bin=mysql-bin 
        2. 为当前节点设置一个全局惟一的ID号
                server-id=1
                innodb_file_per_table=ON
                skip_name_resolve=ON
        3. 创建有复制权限的用户帐号: REPLICATION SLAVE,  REPLICATION CLIENT
            GRANT REPLICATION SLAVE,  REPLICATION CLIENT ON *.* TO 'repluser'@'*' IDENTIFIED BY 'replpass';


    从节点：
        1. 启动中继日志
        2. 为当前节点设置一个全局惟一的ID号
        3. 使用有复制权限的用户帐号连接至主服务器，并启动复制线程；
            vim /etc/my.cnf
            [mysqld]
                relay-log=relay-log
                relay-log-index=relay-log.index
                server-id=2  # 惟一
                innodb_file_per_table=ON
                skip_name_resolve=ON
            CHANGE MASTER TO MASTER_HOST='x.x.x.x',MASTER_USER='repluser',MASTER_PASSWORDWORD='replpass',MASTER_LOG_FILE='mysql-bin.xxxxx',MASTER_LOG_POS=xxx;
            START SLAVE [IO_THREAD|SQL_THREAD]; 

    思考：如果主节点已经运行了一段时间，且有大量数据时，如何配置并启动slave节点：
        理想做法：在主机上做一次备份，记录二进制日志的position，在从服务器上恢复一遍，主从复制指定二进制日志的Postion

    复制架构中应该注意的问题：
        1. 限制从服务器为只读
            在从服务器上设置read_only=ON; 此限制对拥有SUPER权限的用户均无效；
            阻止所有用户：
                mysql> FLUSH TABLES WITH REDA LOCK;
        2. 如何保证主从复制的事务安全？ 
            主服务器在执行事务时，用来执行允许写操作，事务在提交时为了保证数据可用性、可靠性、持久性等特点都应该立即将数据从内存写入到磁盘上， 即便不写入数据文件，也应该写入事务日志中；
            在master节点启用参数：
                sync_binlog=ON  # 遇到事务提交时，必须要将Binlog缓冲区域中记录下来的事件立即刷写到磁盘上的二进制日志文件中去 
                如果用到时的为InnoDB存储引擎：
                    innodb_flush_logs_at_trx_commit=ON   # 在事务提交时，立即将内存中的跟事务相关的数据立即写到事务日志中；
                    innodb_support_xa=ON     # xa分布式事务，做两端式提交
            在slave节点：
                skip_slave_start=ON
                sync_relay_log
                sync_relay_log_info
        


## 主主复制
    互为主从：
        1. 数据不一致；因此，慎用
        2. 自动增长ID：
            配置一个节点使用奇数id;
                auto_increment_offset=1
                auto_increment_increment=2
            另一个节点使用偶数id:
                auto_increment_offset=2
                auto_increment_increment=2
        
    配置步骤：
        1. 各节点使用一个惟一的server_id:
        2. 都启用binary log和relay log；
        3. 都创建拥有复制权限的用户帐号;
        4. 定义自动增长id字段的数值范围为奇偶;
        5. 均把对方指定为主节点，并启动复制线程

        vim /etc/my.cnf
            1. [mysqld]
                log-bin=master-bin
                relay-log=relay-log
                relay-log-index=relay-log.index
                server-id=2  # 惟一
                innodb_file_per_table=ON
                skip_name_resolve=ON
                auto_increment_offset=1
                auto_increment_increment=2
            
                [mysqld]
                log-bin=master-bin
                relay-log=relay-log
                relay-log-index=relay-log.index
                server-id=5  # 惟一
                innodb_file_per_table=ON
                skip_name_resolve=ON
                auto_increment_offset=2
                auto_increment_increment=2
            2. 创建有复制权限的帐号：
                GRANT REPLICATION SLAVE,  REPLICATION CLIENT ON *.* TO 'repluser'@'*' IDENTIFIED BY 'replpass';
                FLUSH PRIVILEGES;
            3. 设置互为主从
                SHOW MASTER;
                CHANGE MASTER TO MASTER_HOST='x.x.x.x',MASTER_USER='repluser',MASTER_PASSWORD='replpass',MASTER_LOG_FILE='mysql-bin.xxxxx',MASTER_LOG_POS=xxx;
                START SLAVE [IO_THREAD|SQL_THREAD]; 



## 半同步复制：多个从节点，只需要等待其中一个节点在复制时，能够把二进制日志文件传递给从节点，从节点本地保存以后并向主节点确认后，主节点才向客户端返回Ok; 剩余的节点依旧可以异步方式同步；如果半同步过程中没有任何一个节点给主节点返回同步完成，主节点设置超时时间
    插件：
        semisync_master
        semisync_slave
    主节点：
        mysql> INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so'
    从节点：
        mysql> INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so'
    创建有复制权限的帐号：
        GRANT REPLICATION SLAVE,  REPLICATION CLIENT ON *.* TO 'repluser'@'*' IDENTIFIED BY 'replpass';
        FLUSH PRIVILEGES;
    启动：
        SET GLOBAL rpl_semi_sync_master_enabled=1
        SET GLOABL rpl_semi_sync_slave_enabled=1
        SHOW GLOBAL STATUS LIKE '%semi%'
        SHOW GLOBAL VARIABLES LIKE '%semi%'


## 复制过滤器
    让从节点仅复制指定的数据库，或指定数据库的指定表；
    有两种实现方式：
        1. 主服务器仅向二进制日志中记录与特定数据库（特定表）相关的事件
            问题：时间还原无法实现；不建议使用

            binlog_do_db=           # 白名单
            binlog_ignore_db=       # 黑名单

        2. 从服务器SQL_THREAD在replay中的中继日志中的事件时，仅读取与特定数据库(特定表)相关的事件并应用于本地      
            问题：会造成网络及磁盘IO浪费；
            replicate_do_db=        # 复制的数据库白名单
            replicate_ignore_db=    # 复制的数据库黑名单
            replicate_do_table=
            replicate_ignore_table=
            replicate_wild_do_db=   # 使用通配符定义
            replicate_wild_ignore_db=



## 基于SSL复制
    前提：支持SSL
    1. master配置证书和私钥：并且创建一个要求必须使用SSL连接的复制帐号
    2. slave端使用CHANGER MASTER TO命令时指明ssl相关选项；

## 跟复制相关的文件：
    master.info：用于保存slave连接至master时的相关信息，例如帐号、密码、服务器等地址
    relay-log.info：保存在当前slave节点上已经复制的当前二进制日志和本地relay log日志的对应关系

## 复制的监控和维护：
    1. 清理日志：除非备份过
        PURGE BINARY LOGS TO ''
    2. 复制监控
        SHOW MASTER STATUS;
        SHOW BINARY EVENTS;
        SHOW BINARY LOGS;
        SHOW SLAVE STATUS;
        SHOW PROCESSLIST;
    3. 从服务器是否落后于主服务器
        Seconds_Behind_Master：0
    4. 如何确定主从节点数据是否一致：
        percona-tools
    5. 数据不一致如何修复:
        重新复制



切分：
    垂直切分：分库
         把一个库的N张表分散到多台物理服务器上，不同的查询写请求发往不同的物理节点；

    水平切分：分表，shading
        将某个访问极其频繁的表再按照某个字段的某种规则来分散到多个表之中，每个表中包含一部分数据；
        cobar，gizzard 

# MySQL Replication

    MMM：Multi Master MySQL 
    MHA：Master HA 
        对主节点进行监控，可实现自动故障转移至其它从节点；通过提升某一从节点为新的主节点
        Manager和node节点
        MHA在监控到master节点故障时，会提升其中拥有最新数据的slave节点成为新的master节点，在此期间，MHA会通过于其它从节点获取额外信息来避免一致性的问题；MHA还提供了master节点的在线切换功能，按需切换master/slave节点；
    Galera Cluster：wresp
        通过wresp协议在全局实现复制：任何一个节点都可读写

## MHA 过程：SSH互信，密钥方式
    ssh-keygen -t rsa -P ''
    cat .ssh/id_rsa.pub >> .ssh/authorized_keys   # 600
    scp .ssh/id_rsa .ssh/authorized_keys XXX:/root/.ssh

    node1：manager节点：
        yum install mha4mysql-manager mha4mysql-node
    node2: 主节点：
        vim /etc/my.cnf
            innodb_file_per_table = 1
            skip_name_resolve = 1
            log-bin = master-bin
            relay-log = relay-bin
            server-id = 1 
        # systemctl start mariadb
        > SHOW MASTER STATUS;
            ###
        > GRANT REPLICATION SLAVE,  REPLICATION CLIENT ON *.* TO 'repluser'@'*' IDENTIFIED BY 'replpass';
        > FLUSH PRIVILEGES;

        主从配置完成后：建立MHA
            > GRANT ALL ON *.* TO 'mhauser'@'X.X.X.X' IDENTIFIED BY 'mhapass';
            > FLUSH PRIVILEGES

        yum install mha4mysql-node

    node3: 从节点
        vim /etc/my.cnf 
            innodb_file_per_table = 1
            skip_name_resolve = 1
            log-bin = master-bin
            relay-log = relay-bin
            server-id = 2
            read_only = 1
            relay_log_purge = 0
        # systemctl start mariadb
        > CHANGE MASTER TO MASTER_HOST='x.x.x.x',MASTER_USER='repluser',MASTER_PASSWORDWORD='replpass',MASTER_LOG_FILE='mysql-bin.xxxxx',MASTER_LOG_POS=xxx;
        > START SLAVE [IO_THREAD|SQL_THREAD]; 

        yum install mha4mysql-node

    node4：从节点
        同node3
        yum install mha4mysql-node

    检测：
        配置文件：每一个主从配置称为一个application
            golbal配置，为各application提供默认配置;
            application 配置： 
                [server default]
                user=mhauser
                passowrd=mhapss
                manager_workdir=/data/masterha/app1
                manager_log=/data/masterha/app1/manager.log
                remote_workdir=/data/masterha/app1
                ssh_user=root
                repl_user=repluser
                repl_password=replpass
                ping_interval=1
                [server1]
                hostname=
                #ssh_port=
                candidate_master=1
                [server2]
                hostname=


## 读写分离：
    mysql-proxy --> Atlas (Qihoo)
    Amoeba 

## 复制的问题和解决方案
    1. 数据损坏或丢失：
        Master： 
            MHA + semi repl 
        Slave: 
            重新复制
    2. 混合使用存储引擎
        MyISAM：不支持事务，无法回滚
        InnoDB：支持事务
        万一，需忍受数据不一致
    3. 不惟一的server id
         重新复制
    4. 复制延迟
        需要额外的监控工具的辅助
        一主多众
        多线程复制
    
## 数据库衡量指标：
    qps：query per Second 
    tps：transaction per second 

    sysbench



# Galera Cluster 
    wresp复制：
    wsrep_provider

    使用Galera Cluster的条件：
        1. 使用msyql官方提供的代码中支持Galera Cluster
        2. 直接使用Galera Cluster官方提供的mysql分支
        3. percona-Cluster分支版本
        4. mariadb-Cluster：整合了Galera，MariaDB-Galera-xxx
    
    1. 至少3个节点，基数节点
    # yum install MariaDB-client MariaDB-shared MariaDB-common MariaDB-Galera-server galera rsync socat

    # 配置
    wsrep_provider = /usr/lib64/galera/libgalera_smm.so
    wsrep_cluster_address = "gcomm://"
    wsrep_cluster_name = "xxx"
    # wsrep_node_name = "xxx"
    # wsrep_node_address = "xxx.xxx.xxxx.xxx"
    binlog_format = row 
    default_storage_engine = InnoDB 
    innodb_autoinc_locak_mode = 2
    bind-address = 0.0.0.0


    # 首次启动时，需要初始化集群，在其中一个节点上执行如下命令：
        /etc/init.d/mysql start --wsrep-new-Cluster
        而后正常启动其它节点即可
    
    # 查看集群中的相关参数：
        SHOW STATUS LIKE 'wsrep_%';
         





GTID：全局事务ID 



MHA优缺点
优点：
    1、MHA自动化主服务器故障转移，快速将从服务器晋级为主服务器(通常在10-30s)，而不影响复制的一致性，不会有性能损耗，容易安装，不必更改现有的部署环境，适用于任何存储引擎。   
    2、MHA提供在线主服务器切换，改变先正运行的主服务器到另外一台上，这个过程只需0.5-2s的时间，这个时间内数据无法写入。MHA Manager通过ssh连接mySQL slave服务器。  
    3、使用半同步复制，可以大大降低数据丢失的风险。MHA可以与半同步复制结合起来。如果只有一个slave已经收到了最新的二进制日志，MHA可以将最新的二进制日志应用于其他所有的slave服务器上，因此他们彼此保持一致性。

缺点：
    1、虽然MHA试图从宕机的主服务器上保存二进制日志，但也会有问题。例如，如果主服务器硬件故障或无法通过ssh访问，MHA没法保存二进制日志，只进行故障转移而丢失最新数据。
    2、当主DB故障，切换到另外的服务器上后，即使恢复了原来的主DB，也不能立即加入整套MHA系统中，得重新部署。而且当发生一次切换后，管理节点的监控进程就会自动退出，需要用脚本来自动启动。另外还得删除app1.failover.complete这个文件，否则新的主DB出现问题MHA就不会切换了。


MMM优缺点
优点：高可用性，扩展性好，出现故障自动切换，对于主主同步，在同一时间只提供一台数据库写操作，保证的数据的一致性。
缺点：Monitor节点是单点，可以结合Keepalived实现高可用。
